{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c001ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "import math\n",
    "\n",
    "\n",
    "def softmax(x, T = 1):\n",
    "    \"\"\"Compute softmax values for each sets of scores in x.\"\"\"\n",
    "    e_x = np.exp((x - np.max(x)) / T)\n",
    "\n",
    "    return e_x / e_x.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0643138d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class fileScore:\n",
    "    \n",
    "    def __init__(self, file_name, option=\"common\"):\n",
    "        \n",
    "        self.file_name = file_name\n",
    "        self.option = option\n",
    "        \n",
    "        self.score = float('.'.join(file_name.split('-')[-1].split('.')[:-1]))\n",
    "        self.filescore = self.make_score_list()\n",
    "\n",
    "    def make_score_list(self):\n",
    "        \n",
    "        fp = open(self.file_name, 'r')\n",
    "        line = fp.readline()\n",
    "            \n",
    "        index, score = line.split(',')\n",
    "        \n",
    "        if index.strip() != \"index\" or score.strip() != \"score\":\n",
    "            print(f\"format error {self.file_name}\")\n",
    "            return []\n",
    "            \n",
    "        filescore = []\n",
    "        if self.option == \"common\":\n",
    "            \n",
    "            line = fp.readline()\n",
    "            while line:\n",
    "                sc = float(line.split(',')[-1])\n",
    "                filescore.append(sc)\n",
    "                line = fp.readline()\n",
    "                \n",
    "        elif self.option == \"temperature\":\n",
    "            T = 3\n",
    "            line = fp.readline()\n",
    "            while line:\n",
    "                sc_1 = float(line.split(',')[-1])\n",
    "                sc_0 = 1 - sc_1\n",
    "                new_sc_1 = sc_1 + 5\n",
    "                new_sc_0 = sc_0 + 5\n",
    "                [new_sc_0, new_sc_1] = softmax([sc_0, sc_1], T)\n",
    "                # print(sc_1, new_sc_1)\n",
    "                \n",
    "                filescore.append(new_sc_1)\n",
    "                line = fp.readline()\n",
    "            \n",
    "                \n",
    "        \n",
    "        return filescore\n",
    "    \n",
    "    def get_train_acc(self):\n",
    "        return self.score\n",
    "    \n",
    "    def get_score_list(self):\n",
    "        return self.filescore\n",
    "    \n",
    "    def get_score_list_idx(self, idx):\n",
    "        return self.filescore[idx]\n",
    "    \n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18f92cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_list(option = \"common\"):\n",
    "    file_list = glob(\"*.txt\")\n",
    "    \n",
    "    file_class = []\n",
    "    for i in file_list:\n",
    "        fc = fileScore(i, option)\n",
    "        file_class.append(fc)\n",
    "    \n",
    "    return file_class\n",
    "       \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41749942",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ground_true_list():\n",
    "    fp = open(\"../ML_storage/test_binary_y.csv\", \"r\")\n",
    "    line = fp.readline()\n",
    "    if line.strip() != \"LiveBirth\":\n",
    "        print(line)\n",
    "        print(\"format error\")\n",
    "    \n",
    "    ground_true = []\n",
    "    line = fp.readline()\n",
    "    \n",
    "    while line:\n",
    "        ground_true.append(int(line))\n",
    "        line = fp.readline()\n",
    "    return ground_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b12faf1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ---------------------------- I am a line ------------------------------------- ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "afe98f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import matplotlib\n",
    "import bob.measure\n",
    "from matplotlib import image as mpimg\n",
    "\n",
    "def generate_det_curve(p_scores, n_scores):\n",
    "        # matplotlib.use('TkAgg')\n",
    "\n",
    "        plt.switch_backend('agg')\n",
    "        bob.measure.plot.det(n_scores, p_scores, 1000, color = (0,0,0), linestyle = '-')\n",
    "        bob.measure.plot.det_axis([0.01, 99, 0.01, 99])\n",
    "        threshold = bob.measure.eer_threshold(n_scores, p_scores)\n",
    "        far, frr = bob.measure.farfrr(n_scores, p_scores, threshold)\n",
    "        \n",
    "        x = range(99)\n",
    "        ax = plt.gca()\n",
    "        #ax.plot(x)\n",
    "        ax.set_aspect('equal', adjustable='box')\n",
    "        plt.plot([100, -10], [100, -10], linestyle='--', label=f\"Equal error rate = {max(far, frr)* 100}%\")\n",
    "        print(\"##########\")\n",
    "        print(max(far, frr) * 100)\n",
    "        print(\"##########\")\n",
    "        plt.xlabel('FAR (%)')\n",
    "        plt.ylabel('FRR (%)')\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.grid(True)\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        \n",
    "        plt.savefig('det_tmp.png')\n",
    "        plt.cla()\n",
    "        plt.clf()\n",
    "        \n",
    "        return max(far, frr) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c5c97192",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.98     27432\n",
      "           1       0.77      0.92      0.84      3773\n",
      "\n",
      "    accuracy                           0.96     31205\n",
      "   macro avg       0.88      0.94      0.91     31205\n",
      "weighted avg       0.96      0.96      0.96     31205\n",
      "\n",
      "0.9575709020990226\n",
      "##########\n",
      "4.002120328650941\n",
      "##########\n"
     ]
    }
   ],
   "source": [
    "# one original result\n",
    "file_class = get_file_list(\"common\")\n",
    "ground_true_list = get_ground_true_list()\n",
    "mix_prediction = []\n",
    "for idx in range(len(ground_true_list)):\n",
    "    mix_prediction.append(c.get_score_list_idx(idx))\n",
    "    \n",
    "hard_prediction = []\n",
    "acc = 0\n",
    "for i in mix_prediction:\n",
    "    if i >= 0.5:\n",
    "        hard_prediction.append(1)\n",
    "    else:\n",
    "        hard_prediction.append(0)\n",
    "\n",
    "for idx in range(len(hard_prediction)):\n",
    "    if ground_true_list[idx] == hard_prediction[idx]:\n",
    "        acc += 1\n",
    "\n",
    "print(classification_report(ground_true_list, hard_prediction))\n",
    "print(acc / len(ground_true_list))\n",
    "\n",
    "ground_true_list = np.array(ground_true_list)\n",
    "hard_prediction = np.array(hard_prediction)\n",
    "mix_prediction = np.array(mix_prediction)\n",
    "\n",
    "p_scores, n_scores = mix_prediction[np.where(ground_true_list == 1)].astype(np.double), mix_prediction[np.where(ground_true_list == 0)[0]].astype(np.double)\n",
    "\n",
    "generate_det_curve(p_scores, n_scores)\n",
    "image = mpimg.imread(\"det_tmp.png\")\n",
    "plt.imshow(image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bf52db9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98     27432\n",
      "           1       0.76      1.00      0.86      3773\n",
      "\n",
      "    accuracy                           0.96     31205\n",
      "   macro avg       0.88      0.98      0.92     31205\n",
      "weighted avg       0.97      0.96      0.96     31205\n",
      "\n",
      "0.9622496394808524\n",
      "0.04024496937882765 0.04028624436787702\n",
      "##########\n",
      "4.028624436787702\n",
      "##########\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11555/358429023.py:40: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "# simple model ensemble\n",
    "\n",
    "file_class = get_file_list(\"common\")\n",
    "ground_true_list = get_ground_true_list()\n",
    "\n",
    "mix_prediction = []\n",
    "\n",
    "for idx in range(len(ground_true_list)):\n",
    "    pred = []\n",
    "    # print(idx)\n",
    "    for c in file_class:\n",
    "        pred.append(c.get_score_list_idx(idx))\n",
    "    \n",
    "    mix_prediction.append(np.mean(pred))\n",
    "\n",
    "hard_prediction = []\n",
    "acc = 0\n",
    "for i in mix_prediction:\n",
    "    if i >= 0.5:\n",
    "        hard_prediction.append(1)\n",
    "    else:\n",
    "        hard_prediction.append(0)\n",
    "\n",
    "for idx in range(len(hard_prediction)):\n",
    "    if ground_true_list[idx] == hard_prediction[idx]:\n",
    "        acc += 1\n",
    "\n",
    "print(classification_report(ground_true_list, hard_prediction))\n",
    "print(acc / len(ground_true_list))\n",
    "\n",
    "ground_true_list = np.array(ground_true_list)\n",
    "hard_prediction = np.array(hard_prediction)\n",
    "mix_prediction = np.array(mix_prediction)\n",
    "\n",
    "p_scores, n_scores = mix_prediction[np.where(ground_true_list == 1)].astype(np.double), mix_prediction[np.where(ground_true_list == 0)[0]].astype(np.double)\n",
    "\n",
    "generate_det_curve(p_scores, n_scores)\n",
    "image = mpimg.imread(\"det_tmp.png\")\n",
    "plt.imshow(image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2357dda3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98     27432\n",
      "           1       0.76      1.00      0.86      3773\n",
      "\n",
      "    accuracy                           0.96     31205\n",
      "   macro avg       0.88      0.98      0.92     31205\n",
      "weighted avg       0.97      0.96      0.96     31205\n",
      "\n",
      "0.9622496394808524\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98     27432\n",
      "           1       0.76      1.00      0.86      3773\n",
      "\n",
      "    accuracy                           0.96     31205\n",
      "   macro avg       0.88      0.98      0.92     31205\n",
      "weighted avg       0.97      0.96      0.96     31205\n",
      "\n",
      "0.9622496394808524\n",
      "0.04024496937882765 0.04028624436787702\n",
      "##########\n",
      "4.028624436787702\n",
      "##########\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11555/964932385.py:76: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "# temperature model ensemble\n",
    "\n",
    "file_class = get_file_list(\"temperature\")\n",
    "ground_true_list = get_ground_true_list()\n",
    "\n",
    "\n",
    "mix_prediction = []\n",
    "\n",
    "for idx in range(len(ground_true_list)):\n",
    "    pred = []\n",
    "    # print(idx)\n",
    "    for c in file_class:\n",
    "        pred.append(c.get_score_list_idx(idx))\n",
    "    \n",
    "    mix_prediction.append(np.mean(pred))\n",
    "    # print(pred)\n",
    "\n",
    "\n",
    "hard_prediction = []\n",
    "acc = 0\n",
    "for i in mix_prediction:\n",
    "    if i >= 0.5:\n",
    "        hard_prediction.append(1)\n",
    "    else:\n",
    "        hard_prediction.append(0)\n",
    "\n",
    "for idx in range(len(hard_prediction)):\n",
    "    if ground_true_list[idx] == hard_prediction[idx]:\n",
    "        acc += 1\n",
    "    else:\n",
    "        pass\n",
    "        # print(mix_prediction[idx], ground_true_list[idx])\n",
    "\n",
    "print(classification_report(ground_true_list, hard_prediction))\n",
    "print(acc / len(ground_true_list))\n",
    "\n",
    "# simple model ensemble\n",
    "\n",
    "file_class = get_file_list(\"common\")\n",
    "ground_true_list = get_ground_true_list()\n",
    "\n",
    "mix_prediction = []\n",
    "\n",
    "for idx in range(len(ground_true_list)):\n",
    "    pred = []\n",
    "    # print(idx)\n",
    "    for c in file_class:\n",
    "        pred.append(c.get_score_list_idx(idx))\n",
    "    \n",
    "    mix_prediction.append(np.mean(pred))\n",
    "\n",
    "hard_prediction = []\n",
    "acc = 0\n",
    "for i in mix_prediction:\n",
    "    if i >= 0.5:\n",
    "        hard_prediction.append(1)\n",
    "    else:\n",
    "        hard_prediction.append(0)\n",
    "\n",
    "for idx in range(len(hard_prediction)):\n",
    "    if ground_true_list[idx] == hard_prediction[idx]:\n",
    "        acc += 1\n",
    "\n",
    "print(classification_report(ground_true_list, hard_prediction))\n",
    "print(acc / len(ground_true_list))\n",
    "\n",
    "ground_true_list = np.array(ground_true_list)\n",
    "hard_prediction = np.array(hard_prediction)\n",
    "mix_prediction = np.array(mix_prediction)\n",
    "\n",
    "p_scores, n_scores = mix_prediction[np.where(ground_true_list == 1)].astype(np.double), mix_prediction[np.where(ground_true_list == 0)[0]].astype(np.double)\n",
    "\n",
    "generate_det_curve(p_scores, n_scores)\n",
    "image = mpimg.imread(\"det_tmp.png\")\n",
    "plt.imshow(image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0d32bfd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98     27432\n",
      "           1       0.76      1.00      0.86      3773\n",
      "\n",
      "    accuracy                           0.96     31205\n",
      "   macro avg       0.88      0.98      0.92     31205\n",
      "weighted avg       0.97      0.96      0.96     31205\n",
      "\n",
      "0.9622496394808524\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98     27432\n",
      "           1       0.76      1.00      0.86      3773\n",
      "\n",
      "    accuracy                           0.96     31205\n",
      "   macro avg       0.88      0.98      0.92     31205\n",
      "weighted avg       0.97      0.96      0.96     31205\n",
      "\n",
      "0.9622496394808524\n",
      "0.04024496937882765 0.04028624436787702\n",
      "##########\n",
      "4.028624436787702\n",
      "##########\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11555/7470373.py:78: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "# Linear model ensemble\n",
    "file_class = get_file_list(\"common\")\n",
    "ground_true_list = get_ground_true_list()\n",
    "\n",
    "s = 0\n",
    "for c in file_class:\n",
    "    s += c.get_train_acc()\n",
    "\n",
    "mix_prediction = []\n",
    "\n",
    "for idx in range(len(ground_true_list)):\n",
    "    mix = 0\n",
    "    # print(idx)\n",
    "    for c in file_class:\n",
    "        mix += (c.get_train_acc()/s) * c.get_score_list_idx(idx) \n",
    "    \n",
    "    mix_prediction.append(mix)\n",
    "    # print(pred)\n",
    "\n",
    "\n",
    "hard_prediction = []\n",
    "acc = 0\n",
    "for i in mix_prediction:\n",
    "    if i >= 0.5:\n",
    "        hard_prediction.append(1)\n",
    "    else:\n",
    "        hard_prediction.append(0)\n",
    "\n",
    "for idx in range(len(hard_prediction)):\n",
    "    if ground_true_list[idx] == hard_prediction[idx]:\n",
    "        acc += 1\n",
    "    else:\n",
    "        pass\n",
    "        # print(mix_prediction[idx], ground_true_list[idx])\n",
    "\n",
    "print(classification_report(ground_true_list, hard_prediction))\n",
    "print(acc / len(ground_true_list))    \n",
    "\n",
    "# simple model ensemble\n",
    "\n",
    "file_class = get_file_list(\"common\")\n",
    "ground_true_list = get_ground_true_list()\n",
    "\n",
    "mix_prediction = []\n",
    "\n",
    "for idx in range(len(ground_true_list)):\n",
    "    pred = []\n",
    "    # print(idx)\n",
    "    for c in file_class:\n",
    "        pred.append(c.get_score_list_idx(idx))\n",
    "    \n",
    "    mix_prediction.append(np.mean(pred))\n",
    "\n",
    "hard_prediction = []\n",
    "acc = 0\n",
    "for i in mix_prediction:\n",
    "    if i >= 0.5:\n",
    "        hard_prediction.append(1)\n",
    "    else:\n",
    "        hard_prediction.append(0)\n",
    "\n",
    "for idx in range(len(hard_prediction)):\n",
    "    if ground_true_list[idx] == hard_prediction[idx]:\n",
    "        acc += 1\n",
    "\n",
    "print(classification_report(ground_true_list, hard_prediction))\n",
    "print(acc / len(ground_true_list))\n",
    "\n",
    "ground_true_list = np.array(ground_true_list)\n",
    "hard_prediction = np.array(hard_prediction)\n",
    "mix_prediction = np.array(mix_prediction)\n",
    "\n",
    "p_scores, n_scores = mix_prediction[np.where(ground_true_list == 1)].astype(np.double), mix_prediction[np.where(ground_true_list == 0)[0]].astype(np.double)\n",
    "\n",
    "generate_det_curve(p_scores, n_scores)\n",
    "image = mpimg.imread(\"det_tmp.png\")\n",
    "plt.imshow(image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "50aaa85f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98     27432\n",
      "           1       0.76      0.99      0.86      3773\n",
      "\n",
      "    accuracy                           0.96     31205\n",
      "   macro avg       0.88      0.97      0.92     31205\n",
      "weighted avg       0.97      0.96      0.96     31205\n",
      "\n",
      "0.9619932703092453\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98     27432\n",
      "           1       0.76      1.00      0.86      3773\n",
      "\n",
      "    accuracy                           0.96     31205\n",
      "   macro avg       0.88      0.98      0.92     31205\n",
      "weighted avg       0.97      0.96      0.96     31205\n",
      "\n",
      "0.9622496394808524\n",
      "0.04024496937882765 0.04028624436787702\n",
      "##########\n",
      "4.028624436787702\n",
      "##########\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11555/3656480123.py:78: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "# Log model ensemble\n",
    "file_class = get_file_list(\"temperature\")\n",
    "ground_true_list = get_ground_true_list()\n",
    "\n",
    "s = 0\n",
    "for c in file_class:\n",
    "    s += math.log(c.get_train_acc(), 2)\n",
    "\n",
    "mix_prediction = []\n",
    "\n",
    "for idx in range(len(ground_true_list)):\n",
    "    mix = 0\n",
    "    # print(idx)\n",
    "    for c in file_class:\n",
    "        mix += (math.log(c.get_train_acc(), 2)/s) * c.get_score_list_idx(idx) \n",
    "    \n",
    "    mix_prediction.append(mix)\n",
    "    # print(pred)\n",
    "\n",
    "\n",
    "hard_prediction = []\n",
    "acc = 0\n",
    "for i in mix_prediction:\n",
    "    if i >= 0.5:\n",
    "        hard_prediction.append(1)\n",
    "    else:\n",
    "        hard_prediction.append(0)\n",
    "\n",
    "for idx in range(len(hard_prediction)):\n",
    "    if ground_true_list[idx] == hard_prediction[idx]:\n",
    "        acc += 1\n",
    "    else:\n",
    "        pass\n",
    "        # print(mix_prediction[idx], ground_true_list[idx])\n",
    "\n",
    "print(classification_report(ground_true_list, hard_prediction))\n",
    "print(acc / len(ground_true_list))\n",
    "\n",
    "# simple model ensemble\n",
    "\n",
    "file_class = get_file_list(\"common\")\n",
    "ground_true_list = get_ground_true_list()\n",
    "\n",
    "mix_prediction = []\n",
    "\n",
    "for idx in range(len(ground_true_list)):\n",
    "    pred = []\n",
    "    # print(idx)\n",
    "    for c in file_class:\n",
    "        pred.append(c.get_score_list_idx(idx))\n",
    "    \n",
    "    mix_prediction.append(np.mean(pred))\n",
    "\n",
    "hard_prediction = []\n",
    "acc = 0\n",
    "for i in mix_prediction:\n",
    "    if i >= 0.5:\n",
    "        hard_prediction.append(1)\n",
    "    else:\n",
    "        hard_prediction.append(0)\n",
    "\n",
    "for idx in range(len(hard_prediction)):\n",
    "    if ground_true_list[idx] == hard_prediction[idx]:\n",
    "        acc += 1\n",
    "\n",
    "print(classification_report(ground_true_list, hard_prediction))\n",
    "print(acc / len(ground_true_list))\n",
    "\n",
    "ground_true_list = np.array(ground_true_list)\n",
    "hard_prediction = np.array(hard_prediction)\n",
    "mix_prediction = np.array(mix_prediction)\n",
    "\n",
    "p_scores, n_scores = mix_prediction[np.where(ground_true_list == 1)].astype(np.double), mix_prediction[np.where(ground_true_list == 0)[0]].astype(np.double)\n",
    "\n",
    "generate_det_curve(p_scores, n_scores)\n",
    "image = mpimg.imread(\"det_tmp.png\")\n",
    "plt.imshow(image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310ee094",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
